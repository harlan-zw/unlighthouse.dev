---
title: Interaction to Next Paint (INP) Guide
description: Master INP optimization with practical fixes for JavaScript execution, DOM operations, and event handlers. Improve responsiveness across your site.
navigation:
  title: INP
icon: i-heroicons-cursor-arrow-rays
publishedAt: 2025-01-18
updatedAt: 2025-01-18
readTime: "9 min"
keywords:
  - interaction to next paint
  - what is inp
  - fix inp
  - javascript performance
tags:
  - performance
  - inp
  - core web vitals
---

::audit-impact{metric="inp"}
::

INP is the [hardest Core Web Vital for mobile users](https://almanac.httparchive.org/en/2024/performance). While 97% of desktop pages pass, only 74% of mobile pages achieve good INP. That 23-point gap matters—mobile users make up [over 60% of web traffic](https://gs.statcounter.com/platform-market-share/desktop-mobile-tablet).

INP [replaced FID as a Core Web Vital on March 12, 2024](https://web.dev/blog/inp-cwv-march-12). The bar got higher: [93% of sites passed FID](https://web.dev/blog/inp-cwv), but FID only measured input delay on the first interaction. INP measures everything—every click, tap, and keypress throughout the entire page session.

## What is INP?

Interaction to Next Paint measures responsiveness—how long it takes for the page to visually respond after a user interacts. Google uses this definition from the Lighthouse audit:

> "Interaction to Next Paint measures page responsiveness, how long it takes the page to visibly respond to user input."

**INP Thresholds:**

| Score | Rating | What It Feels Like |
|-------|--------|-------------------|
| ≤200ms | Good | Instant, responsive |
| 200–500ms | Needs Improvement | Noticeable lag |
| >500ms | Poor | Frustratingly slow |

**Score Weight:** INP doesn't directly affect Lighthouse Performance scores in lab mode. Instead, Lighthouse uses [Total Blocking Time (TBT)](/glossary/tbt) as a proxy, which accounts for **30%** of the score. In field data (CrUX), INP is measured directly.

## What Triggers INP

INP only measures discrete interactions—events that have a clear start and end:

| Interaction Type | Examples |
|-----------------|----------|
| **Clicks** | Button clicks, link clicks, checkbox toggles |
| **Taps** | Mobile screen taps, touch inputs |
| **Key Presses** | Typing in inputs, keyboard shortcuts |

**Not measured:** Scrolling, hovering, and pinch-to-zoom. These are continuous interactions with different performance characteristics.

The browser tracks all qualifying interactions during the page session. Your INP score is typically the worst interaction (or 98th percentile on pages with many interactions).

## Why INP Matters

### User Experience

Users expect instant feedback. [Research shows](https://web.dev/articles/defining-core-web-vitals-thresholds) that delays over 200ms start to feel sluggish. Past 500ms, users assume something is broken.

The consequences of poor INP:

- Users click multiple times, triggering duplicate actions
- Forms feel unresponsive, causing input errors
- E-commerce checkouts get abandoned
- Users perceive your site as low-quality

Since [90% of user time on a page happens after it loads](https://web.dev/articles/inp), INP captures the experience that matters most.

### SEO Impact

INP officially replaced FID as a [Core Web Vital ranking factor on March 12, 2024](https://developers.google.com/search/docs/appearance/core-web-vitals). While FID only measured the *first* interaction, INP influences ranking eligibility by measuring *all* interactions.

For 2025, the bar is strict: Google treats <200ms as the "Good" threshold for ranking boosts. Sites consistently failing this metric may see reduced visibility in competitive search results.

### Industry Benchmarks & Competitive Advantage

Passing Core Web Vitals is harder than it looks. As of mid-2024, [only ~47% of websites passed all Core Web Vitals](https://almanac.httparchive.org/en/2024/performance).

| Sector | INP Pass Rate | Opportunity |
|--------|---------------|-------------|
| **eCommerce** | Low | High - most catalogs are heavy |
| **News/Media** | Medium | High - ad scripts kill INP |
| **B2B SaaS** | High | Low - usually simpler apps |

Fixing INP isn't just about compliance—it's a competitive advantage. If you're in the 47% that pass, you're likely outranking half your competitors on technical merit alone.

### Business Impact

Real-world improvements show direct business correlation:

| Company | INP Change | Business Impact |
|---------|------------|-----------------|
| [Trendyol](https://web.dev/case-studies/trendyol-inp) | 50% reduction | 1% higher click-through rate |
| [The Economic Times](https://web.dev/case-studies/economic-times-inp) | 3x faster | 43% lower bounce rate |
| [redBus](https://web.dev/case-studies/redbus-inp) | 72% reduction | Higher engagement metrics |
| [Taboola](https://web.dev/case-studies/taboola-inp) | Multiple optimizations | 5.5% higher ad click-through |

## Understanding INP Sub-Parts

Every interaction breaks down into three phases. [Presentation delay accounts for ~42% of total INP](https://www.corewebvitals.io/core-web-vitals/interaction-to-next-paint/presentation-delay) on average—often the overlooked bottleneck.

| Phase | What Happens | What Causes Delays |
|-------|--------------|-------------------|
| **Input Delay** | Time waiting for main thread to become free | Long tasks blocking the thread |
| **Processing Duration** | Time running your event handlers | Complex handler logic |
| **Presentation Delay** | Time for browser to render the result | DOM updates, layout, paint |

**The critical insight:** Most developers focus on processing duration because that's their code. But input delay and presentation delay often account for 60%+ of total INP. A perfectly efficient event handler still fails INP if the main thread was blocked or the DOM update triggered expensive layout.

### Try It: Response Time Lab

Click the buttons to feel the difference between fast and slow responses:

::interactive-inp-lab
::

## Common INP Issues

Poor INP stems from a handful of causes. Here are the most impactful:

| Issue | Impact | Difficulty | Fix Time |
|-------|--------|------------|----------|
| [Long-Running JavaScript](/learn-lighthouse/inp/long-running-javascript) | High | Medium | Hours |
| [Heavy DOM Operations](/learn-lighthouse/inp/heavy-dom-operations) | High | Medium | Hours |
| [Third-Party Scripts](/learn-lighthouse/inp/third-party-scripts) | High | Low | Minutes–Hours |
| [Total Blocking Time](/learn-lighthouse/inp/total-blocking-time) | High | Medium | Hours |
| [DOM Size](/learn-lighthouse/inp/dom-size) | Medium | Medium | Hours |
| [Event Handler Delays](/learn-lighthouse/inp/event-handler-delays) | Medium | Low | Minutes |
| [Hydration Issues](/learn-lighthouse/inp/hydration-issues) | Medium | High | Hours–Days |

→ [Diagnose your specific issue](/learn-lighthouse/inp/fix)

## How to Measure INP

### Lab Testing (Proxy)

INP requires real user interaction—you can't measure it with an automated page load. Lab tools use Total Blocking Time (TBT) as a proxy because [TBT correlates twice as well with INP than FID did](https://github.com/GoogleChrome/web.dev/issues/8395).

**Chrome DevTools:**

1. Open DevTools → **Performance** tab
2. Check **"Web Vitals"** in settings
3. Click record → interact with the page → stop recording
4. Look for interaction events and their duration

**Lighthouse:**
Check the TBT score as your INP proxy. The thresholds are:

- **Mobile:** Good ≤200ms, Poor >600ms
- **Desktop:** Good ≤150ms, Poor >350ms

### Field Data (Real Users)

Field data is what Google uses for ranking. It represents actual user experience.

**PageSpeed Insights:**
Enter your URL to see CrUX (Chrome User Experience Report) INP data. This shows real-world performance from Chrome users.

**Search Console:**
The Core Web Vitals report shows which URLs pass or fail INP, grouped by similar pages.

**Web Vitals JavaScript Library:**

```js
import { onINP } from 'web-vitals'

onINP((metric) => {
  console.log('INP:', metric.value, 'ms')
  console.log('Element:', metric.attribution.interactionTarget)
  console.log('Type:', metric.attribution.interactionType)
})
```

To catch regressions automatically, set up [Lighthouse CI](/learn-lighthouse/lighthouse-ci) in your deployment pipeline.

### Mobile vs Desktop Gap

The INP gap between devices is massive:

| Device | Good INP Rate (2024) |
|--------|---------------------|
| Desktop | 97% |
| Mobile | 74% |

This [23-point gap](https://almanac.httparchive.org/en/2024/performance) means mobile optimization is essential. Mobile devices have:

- Slower CPUs that struggle with JavaScript
- Touch events that can trigger more complex handlers
- Limited memory causing more garbage collection pauses

Test on real mobile devices, not just throttled desktop browsers.

## Framework Guides

Framework-specific INP optimizations:

::card-group
  ::card{title="Next.js" icon="i-simple-icons-nextdotjs" to="/frameworks/nextjs/fix-inp"}
  Hydration strategies, Server Components, and useTransition.
  ::
  ::card{title="Nuxt" icon="i-simple-icons-nuxtdotjs" to="/frameworks/nuxt/fix-inp"}
  Payload optimization, lazy hydration, and component islands.
  ::
  ::card{title="React" icon="i-simple-icons-react" to="/frameworks/react/fix-inp"}
  startTransition, useDeferredValue, and avoiding re-render cascades.
  ::
  ::card{title="Vue" icon="i-simple-icons-vuedotjs" to="/frameworks/vue/fix-inp"}
  Reactivity optimization, async components, and computed caching.
  ::
  ::card{title="Svelte" icon="i-simple-icons-svelte" to="/frameworks/svelte/fix-inp"}
  Minimal runtime overhead and smart DOM updates.
  ::
  ::card{title="Angular" icon="i-simple-icons-angular" to="/frameworks/angular/fix-inp"}
  Zone.js optimization, OnPush change detection, and signals.
  ::
::

## Test Your Entire Site

Most tools test one page at a time. That's a problem for INP—different pages have different JavaScript, different event handlers, and different interaction patterns.

Your homepage might pass while your checkout fails. Product pages might be fast until someone opens the image gallery.

[Unlighthouse](/) scans your entire site and shows TBT (INP proxy) scores for every page. You'll see which templates have issues, which pages are outliers, and whether your fixes work at scale.

The CLI is free and runs locally. Cloud adds scheduled monitoring to catch regressions before users report them.

## Related

- [Core Web Vitals Overview](/learn-lighthouse/core-web-vitals)
- [All INP Issues & Fixes](/learn-lighthouse/inp/fix)
- [Fix LCP](/learn-lighthouse/lcp)
- [Fix CLS](/learn-lighthouse/cls)
- [INP Definition](/glossary/inp)
- [TBT Definition](/glossary/tbt)

---
title: The Complete Core Web Vitals Guide
description: Master Core Web Vitals - Google's page experience metrics. Learn LCP, CLS, INP thresholds, how to measure them, and fixes that improve rankings and conversions.
navigation:
  title: Core Web Vitals Guide
icon: i-heroicons-chart-bar
publishedAt: "2025-01-12"
updatedAt: "2025-01-18"
readTime: "14 min"
keywords:
  - core web vitals
  - what are core web vitals
  - core web vitals thresholds
  - largest contentful paint
  - cumulative layout shift
  - interaction to next paint
  - lcp cls inp
  - google page experience
  - web performance metrics
  - lighthouse performance score
tags:
  - performance
  - seo
  - core web vitals
relatedPages:
  - path: /tools/cwv-checker
    title: Core Web Vitals Checker
  - path: /learn-lighthouse/lighthouse-ci
    title: Lighthouse CI Guide
  - path: /learn-lighthouse/bulk-lighthouse-testing
    title: Bulk Lighthouse Testing
  - path: /learn-lighthouse/lcp
    title: Largest Contentful Paint (LCP) Guide
  - path: /learn-lighthouse/cls
    title: Cumulative Layout Shift (CLS) Guide
  - path: /learn-lighthouse/inp
    title: Interaction to Next Paint (INP) Guide
  - path: /tools/lighthouse-score-calculator
    title: Lighthouse Score Calculator
  - path: /glossary/lcp
    title: LCP Definition
  - path: /glossary/cls
    title: CLS Definition
  - path: /glossary/inp
    title: INP Definition
---

Core Web Vitals are Google's metrics for measuring user experience. They became an official [Google ranking factor in June 2021](https://developers.google.com/search/docs/appearance/core-web-vitals) and directly affect both your search visibility and user satisfaction.

As of 2024, only [48% of mobile sites pass all Core Web Vitals](https://almanac.httparchive.org/en/2024/performance), meaning optimizing these metrics gives you a competitive advantage over half the web.

## What Are Core Web Vitals?

Core Web Vitals are three specific metrics that measure loading performance, visual stability, and interactivity:

| Metric | Full Name | Measures | Good | Poor |
|--------|-----------|----------|------|------|
| **LCP** | Largest Contentful Paint | Loading speed | ≤2.5s | >4.0s |
| **CLS** | Cumulative Layout Shift | Visual stability | ≤0.1 | >0.25 |
| **INP** | Interaction to Next Paint | Responsiveness | ≤200ms | >500ms |

These [thresholds are measured at the 75th percentile](https://web.dev/articles/defining-core-web-vitals-thresholds) of page loads—meaning 75% of your visitors must experience "good" scores for your site to pass.

**Important:** [INP replaced FID as a Core Web Vital on March 12, 2024](https://web.dev/blog/inp-cwv-march-12). If you're still optimizing for First Input Delay, you're targeting an outdated metric.

---

## Largest Contentful Paint (LCP)

LCP measures how long it takes for the largest visible content element to render. It's the hardest Core Web Vital to pass—[only 59% of mobile pages achieve good LCP](https://almanac.httparchive.org/en/2024/performance).

### What is a Good LCP Score?

| LCP Time | Rating | What It Means |
|----------|--------|---------------|
| ≤2.5s | Good | Users perceive the page as fast |
| 2.5-4.0s | Needs Improvement | Noticeable delay, some users may bounce |
| >4.0s | Poor | Significant user frustration, high abandonment |

### What Elements Can Be LCP?

The LCP element is the largest image or text block visible in the viewport:

- **Images** (including CSS background images)—[73% of mobile pages have an image as their LCP element](https://almanac.httparchive.org/en/2024/performance)
- **Video poster images** (the thumbnail before playback)
- **Block-level text elements** (headings, paragraphs)
- **SVG elements** containing text or images

### Common LCP Issues

| Issue | Impact | Prevalence |
|-------|--------|------------|
| [Slow server response (TTFB)](/learn-lighthouse/lcp/slow-server-response) | High | Sites with poor LCP average [2,270ms TTFB](https://almanac.httparchive.org/en/2024/performance) |
| [Render-blocking resources](/learn-lighthouse/lcp/render-blocking-resources) | High | CSS and JS that delay first paint |
| [Large unoptimized images](/learn-lighthouse/lcp/large-images) | High | Uncompressed or oversized images |
| [Client-side rendering delays](/learn-lighthouse/lcp/client-side-rendering) | Medium | JavaScript-heavy frameworks |
| [LCP image not prioritized](/learn-lighthouse/lcp/prioritize-lcp-image) | Medium | Missing fetchpriority or preload |

### LCP Business Impact

- [Vodafone improved LCP by 31% and saw 8% more sales](https://web.dev/case-studies/vodafone)
- [NDTV halved their LCP and achieved 50% lower bounce rates](https://web.dev/case-studies/ndtv)
- [Tokopedia reduced LCP by 55% and increased organic traffic by 23%](https://web.dev/case-studies/tokopedia)

→ [Complete LCP Guide](/learn-lighthouse/lcp) | [All LCP Fixes](/learn-lighthouse/lcp#common-lcp-issues)

---

## Cumulative Layout Shift (CLS)

CLS measures unexpected layout shifts during the page lifecycle. It's the easiest Core Web Vital to pass—[79% of mobile sites achieve good CLS](https://almanac.httparchive.org/en/2024/performance).

### What is a Good CLS Score?

| CLS Score | Rating | What It Means |
|-----------|--------|---------------|
| ≤0.1 | Good | Stable layout, minimal shifts |
| 0.1-0.25 | Needs Improvement | Noticeable movement, may frustrate users |
| >0.25 | Poor | Significant layout instability |

CLS is calculated as: **Impact Fraction × Distance Fraction**. A shift affecting 50% of the viewport that moves 25% of the viewport height = 0.5 × 0.25 = 0.125 CLS.

### What Causes Layout Shifts?

| Cause | Impact | Prevalence |
|-------|--------|------------|
| [Images without dimensions](/learn-lighthouse/cls/unsized-images) | High | [66% of mobile pages](https://almanac.httparchive.org/en/2024/performance) have unsized images |
| [Ads and embeds](/learn-lighthouse/cls/ads-embeds-iframes) | High | Third-party content without reserved space |
| [Dynamically injected content](/learn-lighthouse/cls/dynamic-content-injection) | Medium | Banners, notifications, modals |
| [Web fonts causing FOIT/FOUT](/learn-lighthouse/cls/web-fonts-causing-foit) | Medium | Font swapping changes text size |
| [CSS animations](/learn-lighthouse/cls/animations-transitions) | Low | Animations that trigger layout |

### CLS Business Impact

- [Redbus reduced CLS from 1.65 to 0 and saw 80-100% higher mobile conversion](https://web.dev/case-studies/redbus)
- [Yahoo! Japan fixed CLS and achieved 15% more page views per session](https://web.dev/case-studies/yahoo-japan)
- [AliExpress improved CLS and reduced bounce rate by 15%](https://web.dev/case-studies/aliexpress)

→ [Complete CLS Guide](/learn-lighthouse/cls) | [All CLS Fixes](/learn-lighthouse/cls#common-cls-issues)

---

## Interaction to Next Paint (INP)

INP measures how quickly your page responds to user interactions. Unlike FID (which only measured the *first* interaction), INP tracks *all* interactions because [90% of user time on a page is spent after initial load](https://web.dev/articles/inp).

### What is a Good INP Score?

| INP Time | Rating | What It Means |
|----------|--------|---------------|
| ≤200ms | Good | Interactions feel instant |
| 200-500ms | Needs Improvement | Noticeable lag on interactions |
| >500ms | Poor | Sluggish, frustrating experience |

### How INP is Calculated

INP measures the full interaction lifecycle:

1. **Input delay** — Time from user action to event handler start
2. **Processing time** — Time to execute event handlers
3. **Presentation delay** — Time to render the visual update

The reported INP is typically the worst interaction (or 98th percentile for pages with many interactions).

### Common INP Issues

| Issue | Impact | Lab Proxy |
|-------|--------|-----------|
| [Long-running JavaScript](/learn-lighthouse/inp/long-running-javascript) | High | Total Blocking Time (TBT) |
| [Heavy event handlers](/learn-lighthouse/inp/event-handler-delays) | High | Main thread work |
| [Large DOM size](/learn-lighthouse/inp/dom-size) | Medium | DOM nodes >1,400 |
| [Third-party scripts](/learn-lighthouse/inp/third-party-scripts) | Medium | Blocking main thread |
| [Hydration delays](/learn-lighthouse/inp/hydration-issues) | Medium | Framework-specific |

### The INP Gap

While [93% of sites passed FID](https://web.dev/blog/inp-cwv), only [74% pass INP](https://almanac.httparchive.org/en/2024/performance). The desktop vs mobile gap is even more stark: **97% desktop** vs **74% mobile** pass INP.

### INP Business Impact

- [Trendyol reduced INP by 50% and saw 1% increase in click-through rate](https://web.dev/case-studies/trendyol)
- [The Economic Times cut INP by 30% and achieved 50% lower bounce rate](https://web.dev/case-studies/economic-times-inp)
- [redBus improved INP by 75% alongside 7% increase in conversions](https://web.dev/case-studies/redbus-inp)

→ [Complete INP Guide](/learn-lighthouse/inp) | [All INP Fixes](/learn-lighthouse/inp#common-inp-issues)

---

## Other Web Vitals

Beyond the three Core Web Vitals, several other metrics affect your Lighthouse Performance score and user experience.

### First Contentful Paint (FCP)

FCP measures when the first text or image is painted. It's the earliest signal that the page is loading.

| FCP Time | Rating |
|----------|--------|
| ≤1.8s | Good |
| 1.8-3.0s | Needs Improvement |
| >3.0s | Poor |

**Weight in Lighthouse:** 10% of Performance score

FCP issues often share root causes with LCP—fix render-blocking resources and server response time to improve both.

### Speed Index (SI)

Speed Index measures how quickly content is visually populated during page load. It captures the *perceived* loading experience.

| Speed Index | Rating |
|-------------|--------|
| ≤3.4s | Good |
| 3.4-5.8s | Needs Improvement |
| >5.8s | Poor |

**Weight in Lighthouse:** 10% of Performance score

Speed Index improves when above-the-fold content loads progressively rather than all at once.

### Time to First Byte (TTFB)

TTFB measures server responsiveness—the time from request to first byte of response. It's not a Core Web Vital but directly impacts LCP.

| TTFB | Rating |
|------|--------|
| ≤200ms | Good |
| 200-600ms | Needs Improvement |
| >600ms | Poor |

Sites with poor LCP have an [average TTFB of 2,270ms](https://almanac.httparchive.org/en/2024/performance). Fix TTFB first if your server response exceeds 600ms.

→ [Fix Slow Server Response](/learn-lighthouse/lcp/slow-server-response)

### Total Blocking Time (TBT)

TBT measures the total time the main thread was blocked by long tasks (>50ms) between FCP and Time to Interactive. It's a lab proxy for INP.

| TBT | Rating |
|-----|--------|
| ≤200ms | Good |
| 200-600ms | Needs Improvement |
| >600ms | Poor |

**Weight in Lighthouse:** 30% of Performance score—the highest-weighted metric

TBT [correlates twice as well with INP](https://github.com/nicjansma/nic.codes/pull/32) as FID did, making it the best lab metric for predicting real-world interactivity.

→ [Fix Total Blocking Time](/learn-lighthouse/inp/total-blocking-time)

### Lighthouse Performance Score Weights

The overall Lighthouse Performance score is a [weighted average](https://developer.chrome.com/docs/lighthouse/performance/performance-scoring) of five metrics:

| Metric | Weight | Primary Improvement |
|--------|--------|---------------------|
| **TBT** | 30% | Reduce JavaScript, break up long tasks |
| **LCP** | 25% | Optimize images, improve TTFB |
| **CLS** | 25% | Set dimensions, reserve space |
| **FCP** | 10% | Remove render-blocking resources |
| **SI** | 10% | Progressive loading, critical CSS |

**Key insight:** LCP, CLS, and TBT account for **80%** of your score. Focus there first.

→ [Try the Score Calculator](/tools/lighthouse-score-calculator)

---

## How to Measure Core Web Vitals

### Lab Data (Synthetic Testing)

Lab tools test in controlled environments—useful for debugging but [not used by Google for ranking](https://www.debugbear.com/docs/core-web-vitals-ranking-factor).

**Tools:**

- [**Core Web Vitals Checker**](/tools/cwv-checker) — Test any page with lab and field data
- [**LCP Finder**](/tools/lcp-finder) — Identify your LCP element and optimization opportunities
- [**CLS Debugger**](/tools/cls-debugger) — Find and fix layout shift sources
- [**INP Analyzer**](/tools/inp-analyzer) — Diagnose interaction responsiveness issues
- **Chrome DevTools** — Performance panel shows LCP, CLS, and long tasks
- **Lighthouse** — Full performance audit with actionable recommendations
- **WebPageTest** — Filmstrip view and waterfall analysis

For CI/CD integration, [Lighthouse CI](/learn-lighthouse/lighthouse-ci) runs audits on every commit and fails builds when metrics regress.

```bash
npx unlighthouse --site https://your-site.com
```

### Field Data (Real User Monitoring)

Field data from actual visitors is what Google uses for ranking:

- [PageSpeed Insights](https://pagespeed.web.dev) — Shows CrUX data for your URL and origin
- [Search Console](https://search.google.com/search-console) — Core Web Vitals report with URL-level groupings
- [Chrome UX Report (CrUX)](https://developer.chrome.com/docs/crux) — 28-day rolling average of real user data

**Important:** Expect a [28-day delay](https://developer.chrome.com/docs/crux/methodology) between fixes and improved CrUX data.

### Lab vs Field Differences

| Aspect | Lab Data | Field Data |
|--------|----------|------------|
| **Device** | Simulated throttling | Real user devices |
| **Network** | Fixed conditions | Variable connections |
| **Interactions** | Scripted or none | Real user behavior |
| **Use for** | Debugging, CI/CD | SEO ranking, real UX |

Your lab scores may differ significantly from field data. A page can score 95 in Lighthouse but fail Core Web Vitals in the field if real users have slower devices or networks.

---

## Why Core Web Vitals Matter for SEO

Core Web Vitals are a confirmed [Google ranking factor](https://developers.google.com/search/docs/appearance/page-experience).

### Ranking Studies

- [Pages at position 1 are 10% more likely to pass CWV than position 9](https://www.debugbear.com/docs/core-web-vitals-ranking-factor)
- Sites failing Core Web Vitals [rank 3.7 percentage points worse](https://www.sistrix.com/blog/core-web-vitals-is-a-measurable-ranking-factor/) on average
- CWV act as a [tie-breaker when content quality is similar](https://developers.google.com/search/docs/appearance/page-experience)

**You must pass all three metrics** to gain ranking advantage—there's no partial credit.

### User Experience & Conversions

The [Deloitte "Milliseconds Make Millions" study](https://www2.deloitte.com/ie/en/pages/consulting/articles/milliseconds-make-millions.html) found a **0.1 second improvement** in site speed can:

- Increase retail conversions by **8.4%**
- Boost average order value by **9.2%**
- Increase travel conversions by **10.1%**

Google research shows bounce rate increases [32% when load time goes from 1 to 3 seconds](https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/mobile-page-speed-new-industry-benchmarks/), and [90% at 5 seconds](https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/mobile-page-speed-new-industry-benchmarks/).

---

## Current State of the Web (2024)

According to [HTTP Archive 2024 data](https://almanac.httparchive.org/en/2024/performance):

| Metric | Mobile Pass Rate | Desktop Pass Rate |
|--------|------------------|-------------------|
| LCP | 59% | 72% |
| CLS | 79% | 72% |
| INP | 74% | 97% |
| **All Three** | **48%** | **54%** |

The trend is improving: mobile CWV pass rates grew from 31% (2022) to 48% (2024). But over half the web still fails.

---

## Test Your Entire Site

Most tools only test one page. Your homepage might score 100, but what about:

- Product pages with heavy images?
- Blog posts with embedded videos?
- Dynamic pages with JavaScript widgets?

The [2024 Web Almanac](https://almanac.httparchive.org/en/2024/performance) specifically notes that homepage performance is often not representative of an entire site.

```bash
npx unlighthouse --site https://your-site.com
```

---

## Next Steps

1. **Audit** — [Run Unlighthouse](/guide/getting-started/installation) to find issues across all pages
2. **Prioritize** — Fix the highest-impact issues first (TBT, LCP, CLS account for 80% of score)
3. **Automate** — Set up [Lighthouse CI](/learn-lighthouse/lighthouse-ci) to catch regressions before they reach production
4. **Monitor** — Set up continuous monitoring to track real user metrics


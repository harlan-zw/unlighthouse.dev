---
title: Bulk Lighthouse Testing Guide | Unlighthouse
description: How to run Lighthouse audits across your entire website. Test hundreds of pages automatically.
navigation:
  title: Bulk Lighthouse Testing
icon: i-heroicons-squares-2x2
publishedAt: "2025-01-12"
updatedAt: "2025-01-12"
keywords:
  - bulk lighthouse
  - lighthouse entire site
  - site-wide audit
  - lighthouse automation
  - pagespeed insights api
tags:
  - lighthouse
  - auditing
  - automation
---

# Bulk Lighthouse Testing Guide

Run Lighthouse audits on every page of your site, not just the homepage.

## The Problem

Standard Lighthouse tools test one page at a time. But your site has hundreds—maybe thousands—of pages, and the [2024 Web Almanac](https://almanac.httparchive.org/en/2024/performance) specifically added secondary page analysis because **homepage performance is often not representative of the entire site**.

**Your homepage might score 100.** What about:
- Product pages with heavy images?
- Blog posts with embedded videos?
- Category pages with infinite scroll?
- User-generated content pages?

Each page type can have dramatically different performance characteristics.

## The Solution: Unlighthouse

Unlighthouse crawls your site and runs Lighthouse on every page automatically.

```bash
npx unlighthouse --site https://your-site.com
```

## How It Works

1. **Crawl** — Discovers all pages from your sitemap and internal links
2. **Audit** — Runs Lighthouse on each page in parallel
3. **Report** — Interactive report sorted by worst scores

## Installation

No installation required. Use npx:

```bash
npx unlighthouse --site https://your-site.com
```

Or install globally:

```bash
npm install -g unlighthouse
unlighthouse --site https://your-site.com
```

## Configuration

Create `unlighthouse.config.ts`:

```ts
export default {
  site: 'https://your-site.com',
  scanner: {
    // Crawl settings
    maxRoutes: 200,
    samples: 1,
  },
  lighthouse: {
    // Lighthouse settings
    throttling: {
      cpuSlowdownMultiplier: 4,
    },
  },
}
```

## Common Options

| Option | Description | Default |
|--------|-------------|---------|
| `--site` | URL to scan | Required |
| `--urls` | Specific URLs to test | All discovered |
| `--samples` | Runs per URL | 1 |
| `--throttle` | Simulate slow connection | true |

## Filtering Pages

Test specific sections:

```bash
# Only blog pages
npx unlighthouse --site https://your-site.com --urls "/blog/**"

# Exclude admin
npx unlighthouse --site https://your-site.com --exclude "/admin/**"
```

## Reading Results

The report shows:
- **Score distribution** — How many pages are good/needs work/poor
- **Worst pages** — Sorted by score, fix these first
- **Issue breakdown** — Common problems across your site

## Understanding Lab vs Field Data

**Critical distinction:** Google [only uses field data (CrUX) for search ranking](https://www.debugbear.com/docs/core-web-vitals-ranking-factor), not lab scores from Lighthouse.

| Aspect | Lab Data (Lighthouse) | Field Data (CrUX) |
|--------|----------------------|-------------------|
| Source | Simulated tests | Real user visits |
| Used for ranking | No | Yes |
| Best for | Debugging issues | Measuring actual UX |
| Update frequency | Immediate | [28-day rolling average](https://developer.chrome.com/docs/crux/methodology) |

Lab testing with Unlighthouse helps you **find and fix issues**. Then monitor field data to verify improvements reached real users.

## Lighthouse Scoring Methodology

[Lighthouse performance scoring](https://developer.chrome.com/docs/lighthouse/performance/performance-scoring) weights metrics differently:

| Metric | Weight |
|--------|--------|
| Total Blocking Time (TBT) | 30% |
| Largest Contentful Paint (LCP) | 25% |
| Cumulative Layout Shift (CLS) | 25% |
| First Contentful Paint (FCP) | 10% |
| Speed Index | 10% |

Scores are derived from [real website performance data on HTTP Archive](https://developer.chrome.com/docs/lighthouse/performance/performance-scoring):
- 0-49: Poor (red)
- 50-89: Needs Improvement (orange)
- 90-100: Good (green)

## Reducing Score Variability

Lighthouse scores can vary between runs. [Google's guidance](https://developers.google.com/web/tools/lighthouse/variability):

- **Run multiple times** — The median of 5 runs is twice as stable as 1 run
- **Use consistent hardware** — Don't run concurrent tests on the same machine
- **Isolate from third-parties** — External scripts add variance
- **Scale horizontally** — Run on multiple smaller instances rather than one large one

Unlighthouse defaults to running multiple samples and averaging for more stable results.

## CI/CD Integration

Run on every deploy to catch regressions:

```yaml
# GitHub Actions
name: Lighthouse Audit
on: [push]

jobs:
  lighthouse:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run Unlighthouse
        run: npx unlighthouse-ci --site ${{ env.SITE_URL }}
```

Set performance budgets to fail builds when scores drop:

```ts
// unlighthouse.config.ts
export default {
  site: 'https://your-site.com',
  ci: {
    budget: {
      performance: 80,
      accessibility: 90,
    },
  },
}
```

→ [Full CI/CD guide](/automation/github-actions)

## CLI vs Cloud

| Feature | CLI | Cloud |
|---------|-----|-------|
| Bulk scanning | Yes | Yes |
| Local setup | Required | Not required |
| Historical data | No | Yes |
| Scheduled scans | No | Yes |
| Team sharing | No | Yes |
| Alerts on regression | No | Yes |

**Start with CLI.** When you need history, scheduling, and team features, [upgrade to Cloud](/cloud).

## Alternatives Comparison

How Unlighthouse compares to other tools:

| Tool | Bulk Testing | Pricing | Notes |
|------|--------------|---------|-------|
| **Unlighthouse** | Unlimited pages | Free (CLI) | Open source, self-hosted |
| PageSpeed Insights | 1 page/request | Free | [25,000 requests/day API limit](https://developers.google.com/speed/docs/insights/v5/get-started) |
| DebugBear | 10,000/mo | $99/mo | Managed service |
| Calibre | 5 sites | $150/mo | Managed service |
| SpeedCurve | Varies | $20-500/mo | RUM + synthetic |

## Current Web Performance Stats

Context for your scores from [HTTP Archive 2024](https://almanac.httparchive.org/en/2024/performance):

| Metric | Mobile Pass Rate | Desktop Pass Rate |
|--------|------------------|-------------------|
| Core Web Vitals (all 3) | 48% | 54% |
| LCP | 59% | 72% |
| CLS | 79% | 72% |
| INP | 74% | 97% |

If you're beating these numbers, you're ahead of most of the web.

## Best Practices

1. **Test representative pages** — Don't just test the homepage
2. **Run multiple samples** — Average results for stability
3. **Test on realistic hardware** — Use CPU throttling to simulate mobile
4. **Monitor trends** — One-time audits aren't enough
5. **Fix worst pages first** — Greatest impact for least effort
6. **Validate with field data** — Lab scores don't affect ranking

## Next Steps

1. Run your first scan: `npx unlighthouse --site https://your-site.com`
2. Fix the worst pages first
3. [Set up CI/CD](/automation/github-actions) to catch regressions
4. [Try Cloud](/cloud) for ongoing monitoring

## Related

- [Core Web Vitals Guide](/learn-lighthouse/core-web-vitals)
- [Fix LCP](/learn-lighthouse/lcp/fix)
- [Fix CLS](/learn-lighthouse/cls/fix)
- [Fix INP](/learn-lighthouse/inp/fix)
